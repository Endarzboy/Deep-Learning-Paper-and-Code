{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clIFh_guHNFv"
   },
   "source": [
    "> ### EEE4423: Signal Processing Lab\n",
    "\n",
    "# LAB \\#11: Character Generation using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un-_JnG1HNF1"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date:  </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ yscec by 9 PM in the form of [ID_Name_Lab11.ipynb]. </div></h4>\n",
    "\n",
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nats-XhJHNF2"
   },
   "source": [
    "<h2><span style=\"color:blue\">2014142243 차현수</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Unidecode in /home/stephencha/anaconda3/envs/py38/lib/python3.8/site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DUNE2wXfHNF2",
    "outputId": "cf8804ce-9063-463d-988f-cd900bd149b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2021-05-19 21:47:22.607872\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J8vQvyjWHNF5"
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9OP9XM9HNF5"
   },
   "source": [
    "These sorts of generative models form the basis of machine translation, image captioning, question answering and more.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=16E7HG_dCyfTo9u9qrrhp2eClq6xK6-f_\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YQl92mwHNF6"
   },
   "source": [
    "### 1. Prepare data\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymNU_-ZGHNF6"
   },
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=171lX3vxj60AQNScQi872BHx2Rz6J7-3J\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TFK9sT_1HNF6",
    "outputId": "1bbcf9b6-7367-4aba-ff59-7a3e6134441d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 4063\n"
     ]
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('dataset/lab11/lose_yourself_eminem.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUyRw-C2HNF6"
   },
   "source": [
    "To make inputs out of this big string of data, we will be splitting it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6nPqv8tuHNF7",
    "outputId": "2a05a019-0267-43fd-9e6a-cbcf9c5ac4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back to the lab again yo, this whole rhapsody\n",
      "He better go capture this moment and hope it don't pass him\n",
      "You better lose yourself in the music, the moment\n",
      "You own it, you better never let it go\n",
      "You on\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScRzeDr8HNF9"
   },
   "source": [
    "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TylqhpuyHNF9",
    "outputId": "9e4b9d7e-bea0-41a5-d853-caaa711be679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "abcDEF is changed to  tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "all_characters = string.printable\n",
    "print(all_characters)\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print('abcDEF is changed to ', char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1XvIwnaHNF9"
   },
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YfaPPbDMHNF-"
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inputs = char_tensor(chunk[:-1])\n",
    "    targets = char_tensor(chunk[1:])\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaQ88mGNHNF-"
   },
   "source": [
    "### 2. Build the LSTM model [4 points]\n",
    "\n",
    "#### [Diagram of LSTM]\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1baQ6Ffu-vDcXbOEBYGeLzhmfvaj4DGgW\" style=\"width: 800px;\"/>\n",
    "LSTM consists of cell state, hidden state and 3 gates that modify or use the cell state. The cell state is the key part of the LSTM and you can think that information \"flows\" in there. The operation of 3 gates are described in below.\n",
    "\n",
    "#### [Forget Gate]\n",
    "The forget gate determines which information in the cell state should be erased.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1sJisl5P0hggmvH4qrcYgSETFKdFdBSH_\" style=\"width: 600px;\"/>\n",
    "\n",
    "#### [Input Gate]\n",
    "First, the candidate cell state is created using the current input and the previous hidden state. And the input gate determines how much the candidate cell state is reflected to the cell state.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1Df-k5FORGH7PnXauYcb8qqUpY3Uot9A7\" style=\"width: 600px;\"/>\n",
    "\n",
    "#### [Output Gate]\n",
    "The output gate determines which elements should be extracted from the cell state to produce the output.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1JLCGPcrZLOYfjyJhMTvmfixHq5plFj8L\" style=\"width: 600px;\"/>\n",
    "\n",
    "The above expression is summarized as follows,\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1kGq8DwwzizuNcg6GF0GaP1DAu26FFlrB\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my4efNewHNF-"
   },
   "source": [
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one LSTM layer that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nDOFfcpsHNF-",
    "outputId": "82c1c3f6-2ca7-464a-d3d6-ae601daea999"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (encoder): Embedding(100, 100)\n",
       "  (sigmoid1): Sigmoid()\n",
       "  (weight_fx): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (weight_fh): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (sigmoid2): Sigmoid()\n",
       "  (weight_ix): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (weight_ih): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (tanh1): Tanh()\n",
       "  (weight_Cx): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (weight_Ch): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (sigmoid3): Sigmoid()\n",
       "  (weight_ox): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (weight_oh): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (tanh2): Tanh()\n",
       "  (decoder): Linear(in_features=100, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        # lstm\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        \n",
    "        # Forget Gate\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.weight_fx = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.weight_fh = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        \n",
    "        # Input Gate\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "        self.weight_ix = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.weight_ih = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.weight_Cx = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.weight_Ch = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        \n",
    "        # Output Gate\n",
    "        self.sigmoid3 = nn.Sigmoid()\n",
    "        self.weight_ox = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.weight_oh = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        \n",
    "        self.tanh2 = nn.Tanh()\n",
    "        #############\n",
    "        \n",
    "        # Readout Layer\n",
    "        self.decoder = nn.Linear(hidden_dim, output_dim, bias=False)\n",
    "    \n",
    "    def forward(self, input, hn, cn):\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        for t in range(input.size()[0]):\n",
    "            embeds = self.encoder(input[t])\n",
    "            # Forget Gate\n",
    "            f = self.sigmoid1(self.weight_fx(embeds) + self.weight_fh(hn[0,:,:]))\n",
    "            \n",
    "            # Input Gate\n",
    "            i = self.sigmoid2(self.weight_ix(embeds) +self.weight_ih(hn[0,:,:]))\n",
    "            c_hat = self.tanh1(self.weight_Cx(embeds) + self.weight_Ch(hn[0,:,:]))\n",
    "\n",
    "            # Output Gate\n",
    "            o = self.sigmoid3(self.weight_ox(embeds) + self.weight_oh(hn[0,:,:]))\n",
    "\n",
    "            # Summarized\n",
    "            cn = f * cn[0,:,:] + i * c_hat\n",
    "            cn = cn.unsqueeze(dim=0)\n",
    "            hn = o * self.tanh2(cn[0,:,:])\n",
    "            hn = hn.unsqueeze(dim=0)\n",
    "        \n",
    "        output = self.decoder(hn[0,:,:])\n",
    "        #############\n",
    "        return output, hn, cn\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # The size of h0, c0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim).cuda()) # initial hidden state\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim).cuda()) # initial cell state\n",
    "        #############\n",
    "        return h0, c0\n",
    "    \n",
    "hidden_dim = 100\n",
    "n_layers = 1\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "model = LSTMModel(n_characters, hidden_dim, n_layers, n_characters)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qajoki2HNF_"
   },
   "source": [
    "### 3. loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xvm-picHHNF_"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5haXxzwOHNF_"
   },
   "source": [
    "### 4 . Write the character level generation code [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JKkMfsh1HNF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str='W', predict_len=100):\n",
    "    # suppose prims_str is a single character\n",
    "    # and use greedy search to predict the next character\n",
    "\n",
    "    hn, cn = model.init_hidden()\n",
    "    predicted = str()\n",
    "    \n",
    "    for i in range(predict_len):\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        predicted += prime_str\n",
    "        temp_predicted = predicted\n",
    "        \n",
    "        temp_predicted = char_tensor(temp_predicted)\n",
    "        temp_predicted = temp_predicted.cuda()\n",
    "        \n",
    "        output, hn, cn = model(temp_predicted, hn, cn)\n",
    "        temp_prime = output.argmax().item()\n",
    "        prime_str = all_characters[temp_prime]\n",
    "        #############\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WA[=cM\\x0b-I%x{tMv%*#\\x0c^2B(Iwo'v%x2r:rx2r0B('DA7*#\\x0c^2B(Iwo'v%x2r:rx2r0B('DA7*#\\x0c^2B(Iwo'v%x2r:rx2r0B('DA7\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt4VFJd5HNF_"
   },
   "source": [
    "### 5 . Write the code to train the model [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LC0xsnlRHNF_",
    "outputId": "069881bd-f136-4501-fcbc-e8bb0bf3afbd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* epoch100 *************************\n",
      "loss 446.8629\n",
      "I the mome the mome the mome the mome the mome the mome the mome the mome the mome the mome the mome \n",
      "\n",
      "************************* epoch200 *************************\n",
      "loss 178.5768\n",
      "I better life the better life the better life the better life the better life the better life the be \n",
      "\n",
      "************************* epoch300 *************************\n",
      "loss 120.8945\n",
      "I better never life it, you better never life it, you better never life it, you better never life it \n",
      "\n",
      "************************* epoch400 *************************\n",
      "loss 293.3300\n",
      "I better\n",
      "You better lose yourself in the moment\n",
      "You own it, you better\n",
      "You better\n",
      "You better\n",
      "You bet \n",
      "\n",
      "************************* epoch500 *************************\n",
      "loss 245.4014\n",
      "It only get one shot, he's no the moment\n",
      "You own it, you better\n",
      "He's no the moment\n",
      "You own it, you b \n",
      "\n",
      "************************* epoch600 *************************\n",
      "loss 178.6050\n",
      "It only get one shot, do not miss your chance to blow\n",
      "This opportunity comes once in a lifetime you  \n",
      "\n",
      "************************* epoch700 *************************\n",
      "loss 169.0504\n",
      "It but he knows his orld one shot, do not miss your chance to blow\n",
      "This opportunity comes once in a  \n",
      "\n",
      "************************* epoch800 *************************\n",
      "loss 195.2574\n",
      "It borman da\n",
      "So the pain a lifetime you better\n",
      "You better lose yourself in the music, the moment\n",
      "You \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    #############\n",
    "    # CODE HERE #\n",
    "    #############\n",
    "    # Load text\n",
    "    inputs, targets = random_training_set()\n",
    "    if inputs.size()[0] < 200: continue\n",
    "    \n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = 0\n",
    "    hn, cn = model.init_hidden()\n",
    "    \n",
    "    for i in range(inputs.size()[0]):\n",
    "        outputs, hn, cn = model(inputs[i].unsqueeze(dim=0), hn, cn)\n",
    "        # print(outputs.size())\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss += criterion(outputs, targets[i].unsqueeze(dim=0))\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_avg += loss.item() / chunk_len\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('*'*25, 'epoch%d'%epoch, '*'*25)\n",
    "        print('loss %.4f'%loss.item())\n",
    "        print(evaluate('I', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "\n",
    "\n",
    "#################################################\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCGRgEuZHNF_"
   },
   "source": [
    "### *References*\n",
    "[1] [practical pytorch](https://github.com/spro/practical-pytorch)(https://github.com/spro/practical-pytorch)\n",
    "\n",
    "[2] [CS 231n](http://cs231n.stanford.edu/syllabus.html)(http://cs231n.stanford.edu/syllabus.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EEE4423_lab10_Character Generation using LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
